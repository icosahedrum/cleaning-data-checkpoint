{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 2,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Checkpoint Three: Cleaning Data\n",
    "\n",
    "Now you are ready to clean your data. Before starting coding, provide the link to your dataset below.\n",
    "\n",
    "My dataset:\n",
    "\n",
    "Import the necessary libraries and create your dataframe(s)."
   ],
   "metadata": {
    "azdata_cell_guid": "26037d32-2047-4157-81ef-595916bd66a0"
   },
   "attachments": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# boilerplate copy-in for various EDA libraries - can optimize later as needed\n",
    "\n",
    "df22 = pd.read_csv(r'C:\\Users\\chris\\PycharmProjects\\eda-checkpoint\\BACI_HS22_V202501 Data\\BACI_HS22_Y2022_V202501.csv', dtype={'k':'str'}) # data for 2022\n",
    "\n",
    "df23 = pd.read_csv(r'C:\\Users\\chris\\PycharmProjects\\eda-checkpoint\\BACI_HS22_V202501 Data\\BACI_HS22_Y2023_V202501.csv', dtype={'k':'str'}) # data for 2023\n",
    "\n",
    "country_codes = pd.read_csv(r'C:\\Users\\chris\\PycharmProjects\\eda-checkpoint\\BACI_HS22_V202501 Data\\country_codes_V202501.csv') # country code keys\n",
    "\n",
    "product_codes = pd.read_csv(r'C:\\Users\\chris\\PycharmProjects\\eda-checkpoint\\BACI_HS22_V202501 Data\\product_codes_HS22_V202501.csv', dtype= str) # product code keys\n",
    "\n",
    "# used absolute paths for absolute certainty"
   ],
   "metadata": {
    "azdata_cell_guid": "e8adef8e-d0f2-4640-a179-5997f11e82ca",
    "ExecuteTime": {
     "end_time": "2025-12-07T17:15:18.998560Z",
     "start_time": "2025-12-07T17:15:12.568746Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T17:20:01.124290Z",
     "start_time": "2025-12-07T17:19:59.290789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.concat([df22, df23])\n",
    "\n",
    "rename_map = {\n",
    "    \"t\": \"year\",\n",
    "    \"i\": \"exporter\",\n",
    "    \"j\": \"importer\",\n",
    "    \"k\": \"product\",\n",
    "    \"v\": \"value\",\n",
    "    \"q\": \"quantity\"\n",
    "}\n",
    "\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "df.info()\n",
    "df.head()\n",
    "\n",
    "# boilerplate column renames for clarity"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22192308 entries, 0 to 11232738\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   year      int64  \n",
      " 1   exporter  int64  \n",
      " 2   importer  int64  \n",
      " 3   product   object \n",
      " 4   value     float64\n",
      " 5   quantity  float64\n",
      "dtypes: float64(2), int64(3), object(1)\n",
      "memory usage: 1.2+ GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   year  exporter  importer product  value  quantity\n",
       "0  2022         4        20  210610  0.412     0.002\n",
       "1  2022         4        20  210690  0.070     0.001\n",
       "2  2022         4        20  271000  6.985     8.103\n",
       "3  2022         4        20  843131  0.354     0.022\n",
       "4  2022         4        31  080211  2.250     0.500"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>exporter</th>\n",
       "      <th>importer</th>\n",
       "      <th>product</th>\n",
       "      <th>value</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>210610</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>210690</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>271000</td>\n",
       "      <td>6.985</td>\n",
       "      <td>8.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>843131</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>080211</td>\n",
       "      <td>2.250</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Missing Data\n",
    "\n",
    "Test your dataset for missing data and handle it as needed. Make notes in the form of code comments as to your thought process."
   ],
   "metadata": {
    "azdata_cell_guid": "e172475a-c4ee-414a-8367-9965355dbba6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"CEPI Data:\")\n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "\n",
    "print('\\nProduct Codes:')\n",
    "for col in product_codes.columns:\n",
    "    pct_missing = np.mean(product_codes[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "\n",
    "print('\\nCountry Codes:')\n",
    "for col in country_codes.columns:\n",
    "    pct_missing = np.mean(country_codes[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "\n",
    "# Used for loops to iterate through both dataframe in order to identify the % of nulls per column - a cleaner way to visualize nulls than .info\n",
    "\n",
    "# Nothing alarming"
   ],
   "metadata": {
    "azdata_cell_guid": "e1dc66ef-e471-4c27-92e7-ee878c106eba",
    "ExecuteTime": {
     "end_time": "2025-12-07T17:20:29.249270Z",
     "start_time": "2025-12-07T17:20:28.633467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEPI Data:\n",
      "year - 0%\n",
      "exporter - 0%\n",
      "importer - 0%\n",
      "product - 0%\n",
      "value - 0%\n",
      "quantity - 4%\n",
      "\n",
      "Product Codes:\n",
      "code - 0%\n",
      "description - 0%\n",
      "\n",
      "Country Codes:\n",
      "country_code - 0%\n",
      "country_name - 0%\n",
      "country_iso2 - 2%\n",
      "country_iso3 - 0%\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Irregular Data\n",
    "\n",
    "Detect outliers in your dataset and handle them as needed. Use code comments to make notes about your thought process."
   ],
   "metadata": {
    "azdata_cell_guid": "1233f543-e9a0-4f78-96f5-d7536554102e"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T18:01:13.133688Z",
     "start_time": "2025-12-07T18:01:01.268390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.describe() # checking the distribution of the data\n",
    "\n",
    "df['value'].describe() # check for insane values\n",
    "\n",
    "df['quantity'].describe() # check for insane values\n",
    "\n",
    "df['year'].unique() # checking for no irregular years\n",
    "\n",
    "missing_mask = ~df['product'].isin(product_codes['code'])\n",
    "missing_rows = df[missing_mask]\n",
    "print(missing_rows) # no product codes are unmapped"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [year, exporter, importer, product, value, quantity, product length]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Unnecessary Data\n",
    "\n",
    "Look for the different types of unnecessary data in your dataset and address it as needed. Make sure to use code comments to illustrate your thought process."
   ],
   "metadata": {
    "azdata_cell_guid": "6f5b8ee0-bab3-44bc-958a-67d1e4c0407f"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_duplicate_occurrences = df.duplicated(keep='first').sum()\n",
    "print(\"Duplicate rows (excluding first occurrences), CEPI data:\", int(num_duplicate_occurrences))\n",
    "\n",
    "num_duplicate_occurrences = product_codes.duplicated(keep='first').sum()\n",
    "print(\"Duplicate rows (excluding first occurrences, product codes):\", int(num_duplicate_occurrences))\n",
    "\n",
    "num_duplicate_occurrences = country_codes.duplicated(keep='first').sum()\n",
    "print(\"Duplicate rows (excluding first occurrences, country codes):\", int(num_duplicate_occurrences))\n",
    "\n",
    "# checking for entire-row-level duplicates\n",
    "\n",
    "# from the results of my EDA, I'm only initially going to focus on the following product codes, making all the other product codes unnecessary: keycodes = ['381800', '848610', '848620', '848640', '851419', '852351', '852352', '852359', '854110', '854121', '854129', '854190', '854231', '854232', '854233', '854239', '854290', '903082', '903141']"
   ],
   "metadata": {
    "azdata_cell_guid": "e788a239-2fbf-41de-9bd3-19e52e3b187c",
    "ExecuteTime": {
     "end_time": "2025-12-07T17:22:27.161998Z",
     "start_time": "2025-12-07T17:22:17.331629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows (excluding first occurrences), CEPI data: 0\n",
      "Duplicate rows (excluding first occurrences, product codes): 0\n",
      "Duplicate rows (excluding first occurrences, country codes): 0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inconsistent Data\n",
    "\n",
    "Check for inconsistent data and address any that arises. As always, use code comments to illustrate your thought process."
   ],
   "metadata": {
    "azdata_cell_guid": "53e0cf94-c68a-4fa0-9849-9505a66bcce6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# During my EDA, I discovered that pandas will remove trailing zeroes from certain datatypes. So I had pandas read those columns as strings as to avoid removing my precious leading zeroes. That was the only thing that was inconsistent. Here's a bunch of code I used to doublecheck that the trailing zeroes were in place and that my relevant columns contained 6-digits as specified by the readme.\n",
    "\n",
    "product_codes['code length'] = product_codes['code'].str.len()\n",
    "\n",
    "unique_pc_lengths = product_codes['code length'].unique()\n",
    "\n",
    "print(unique_pc_lengths) # this was to confirm that all my product codes were 6 digits long\n",
    "\n",
    "df['product length'] = df['product'].str.len()\n",
    "\n",
    "unique_pc_lengths_df = df['product length'].unique()\n",
    "\n",
    "print(unique_pc_lengths_df) # this was to confirm that all my product codes were 6 digits long in the df"
   ],
   "metadata": {
    "azdata_cell_guid": "e9de6624-812a-43f8-8e20-93b4a49b091f",
    "ExecuteTime": {
     "end_time": "2025-12-07T17:28:19.790724Z",
     "start_time": "2025-12-07T17:28:16.304925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n",
      "[6]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summarize Your Results\n",
    "\n",
    "Make note of your answers to the following questions.\n",
    "\n",
    "1. Did you find all four types of dirty data in your dataset? No, 3 out of 4 found. Missing: found and safely ignored; Irregular: not found; Unnecessary: found and cleaned; Inconsistent: found and cleaned.\n",
    "2. Did the process of cleaning your data give you new insights into your dataset? Yes, it helped me learn the importance of the leading zeroes in the product codes of this dataset. It helped me understand more fully that it is near-spotless and normally distributed (for the type of data it represents).\n",
    "3. Is there anything you would like to make note of when it comes to manipulating the data and making visualizations? I'll need to subset the concatenated dataframe into whole vs. the relevant part (Taiwan) for the product codes we've deemed relevant in 'keycodes'. Fairly certain I'll be able to do all of that in Tableau once I make a smaller .csv that contains strictly the data relevant to this analysis. Which should be easy to do thanks to our EDA and cleaning."
   ],
   "metadata": {
    "azdata_cell_guid": "dedc0bfe-17d0-40b2-914f-2ddb54f9ce0d"
   }
  }
 ]
}
